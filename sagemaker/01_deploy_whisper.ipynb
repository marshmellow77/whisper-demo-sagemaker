{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff31f4ac",
   "metadata": {},
   "source": [
    "# Deploying the model to an endpoint\n",
    "In this notebook we will deploy an endpoint with the model whisper-large-v2. We will write our inference code because we will use Whisper's API rather than the Hugging Face API. This is because the Whisper API allows for transcriptions longer than 30 seconds out of the box. The API can be found here: https://github.com/openai/whisper#python-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93d8136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model’: File exists\n",
      "mkdir: cannot create directory ‘model/code’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir model\n",
    "!mkdir model/code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14338e",
   "metadata": {},
   "source": [
    "We write out custome inference code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d67c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/code/inference.py\n",
    "import whisper\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = whisper.load_model(\"large-v2\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_fn(audio_bytes, model):\n",
    "    audio_file = \"tmp.mp3\"\n",
    "    \n",
    "    with open(audio_file, \"wb\") as binary_file:\n",
    "        binary_file.write(audio_bytes['inputs'])\n",
    "        \n",
    "    result = model.transcribe(audio_file)\n",
    "\n",
    "    # print the recognized text\n",
    "    return {\"detected_language\": result[\"language\"], \"transcription\": result[\"text\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0609c26",
   "metadata": {},
   "source": [
    "And into the `requirements.txt` we put the libraries we will need to run the inference code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9a9311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/code/requirements.txt\n",
    "git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b9548d",
   "metadata": {},
   "source": [
    "## Uploading the model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8d752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/whisper-demo-sagemaker/sagemaker/model\n"
     ]
    }
   ],
   "source": [
    "%cd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0feb2d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/requirements.txt\n",
      "code/inference.py\n",
      "model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!tar zcvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b19eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7e9725d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::905847418383:role/service-role/AmazonSageMaker-ExecutionRole-20210804T091905'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be9578c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_location = f\"s3://{sagemaker_session_bucket}/whisper/model/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20875b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./model.tar.gz to s3://sagemaker-us-east-1-905847418383/whisper/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp model.tar.gz $s3_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04cb68",
   "metadata": {},
   "source": [
    "## Deplying the model to en endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf9a1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "# from sagemaker.utils import name_from_base\n",
    "from sagemaker.serializers import DataSerializer\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_location,\n",
    "   role=role,\n",
    "   transformers_version=\"4.17\",\n",
    "   pytorch_version=\"1.10\",\n",
    "   py_version='py38',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34918fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--"
     ]
    }
   ],
   "source": [
    "endpoint_name = \"whisper-large-v2\"\n",
    "audio_serializer = DataSerializer(content_type='audio/x-audio')\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=audio_serializer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15baf0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa47d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"mpthreetest.mp3\"\n",
    "\n",
    "res = predictor.predict(data=audio_path)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda1fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
