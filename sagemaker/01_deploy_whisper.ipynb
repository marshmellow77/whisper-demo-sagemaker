{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c109bb0",
   "metadata": {},
   "source": [
    "# Deploying the model to an endpoint\n",
    "In this notebook we will deploy an endpoint with the model whisper-large-v2. We will write our inference code because we will use Whisper's API rather than the Hugging Face API. This is because the Whisper API allows for transcriptions longer than 30 seconds out of the box. The API can be found here: https://github.com/openai/whisper#python-usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01113084",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model\n",
    "!mkdir model/code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f77678",
   "metadata": {},
   "source": [
    "We write out custome inference code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14df4509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model/code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/code/inference.py\n",
    "import whisper\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = whisper.load_model(\"large-v2\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_fn(audio_bytes, model):\n",
    "    audio_file = \"tmp.mp3\"\n",
    "    \n",
    "    with open(audio_file, \"wb\") as binary_file:\n",
    "        binary_file.write(audio_bytes['inputs'])\n",
    "        \n",
    "    result = model.transcribe(audio_file)\n",
    "\n",
    "    # print the recognized text\n",
    "    return {\"detected_language\": result[\"language\"], \"transcription\": result[\"text\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa28c29",
   "metadata": {},
   "source": [
    "And into the `requirements.txt` we put the libraries we will need to run the inference code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f549fa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model/code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/code/requirements.txt\n",
    "git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ff732",
   "metadata": {},
   "source": [
    "## Uploading the model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012f3b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/whisper-demo-sagemaker/model\n"
     ]
    }
   ],
   "source": [
    "%cd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d7d3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/requirements.txt\n",
      "code/inference.py\n"
     ]
    }
   ],
   "source": [
    "!tar zcvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c2de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33552371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::905847418383:role/service-role/AmazonSageMaker-ExecutionRole-20210804T091905'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1510f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_location = f\"s3://{sagemaker_session_bucket}/whisper/model/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3b72e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./model.tar.gz to s3://sagemaker-us-east-1-905847418383/whisper/model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp model.tar.gz $s3_location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d51dbd",
   "metadata": {},
   "source": [
    "## Deplying the model to en endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c09e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.serializers import DataSerializer\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_location,\n",
    "   role=role,\n",
    "   transformers_version=\"4.17\",\n",
    "   pytorch_version=\"1.10\",\n",
    "   py_version='py38',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa9af68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "endpoint_name = name_from_base(\"whisper-large-v2\")\n",
    "audio_serializer = DataSerializer(content_type='audio/x-audio')\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=audio_serializer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "504d7e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/whisper-demo-sagemaker\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f59873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detected_language': 'en', 'transcription': ' Okay, we are trying this for a second time to test the ability to upload an MP3 file. Hopefully this will work.'}\n"
     ]
    }
   ],
   "source": [
    "audio_path = \"mpthreetest.mp3\"\n",
    "\n",
    "res = predictor.predict(data=audio_path)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae179226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
